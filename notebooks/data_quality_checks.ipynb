{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Assessment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary to import db_connector script\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Add project root to sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "from db_connector import load_from_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_from_excel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines data quality assessment function:\n",
    "\n",
    "def assess_data_quality(df, table_name):\n",
    "    print(f\"\\n{'='*30} {table_name.upper()} DATA QUALITY {'='*30}\")\n",
    "\n",
    "    # 1. Check for duplicates\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"\\n1. Duplicates: {duplicates} ({duplicates/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    # 2. Check for missing values\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = df.isnull().sum() / len(df) * 100\n",
    "    missing_info = pd.DataFrame({\n",
    "        'Missing Values': missing,\n",
    "        'Percentage': missing_pct\n",
    "    })\n",
    "    print(\"\\n2. Missing Values:\")\n",
    "    display(missing_info[missing_info['Missing Values'] > 0].sort_values('Missing Values', ascending=False))\n",
    "    \n",
    "    # 3. Check data types\n",
    "    print(\"\\n3. Data Types:\")\n",
    "    display(pd.DataFrame(df.dtypes, columns=['Data Type']))\n",
    "    \n",
    "    # 4. Specific checks based on table\n",
    "    print(\"\\n4. Specific Quality Checks:\")\n",
    "\n",
    "    if table_name == 'requisitions':\n",
    "        # a. Check for requisitions with close date before open date\n",
    "        if 'OPEN_DATE' in df.columns and 'CLOSE_DATE' in df.columns:\n",
    "            invalid_dates = df[df['CLOSE_DATE'].notna() & (df['CLOSE_DATE'] < df['OPEN_DATE'])]\n",
    "            print(f\"   - Requisitions with close date before open date: {len(invalid_dates)}\")\n",
    "            if len(invalid_dates) > 0:\n",
    "                display(invalid_dates.head())\n",
    "        \n",
    "        # b. Check for unusual number of openings\n",
    "        if 'NUMBER_OF_OPENINGS' in df.columns:\n",
    "            unusual_openings = df[df['NUMBER_OF_OPENINGS'] > 10]  \n",
    "            print(f\"   - Requisitions with more than 10 openings: {len(unusual_openings)}\")\n",
    "            if len(unusual_openings) > 0:\n",
    "                value_counts = df['NUMBER_OF_OPENINGS'].value_counts().sort_index()\n",
    "                display(value_counts)\n",
    "            \n",
    "    elif table_name == 'candidate':\n",
    "        # a. Check for candidates with status dates out of order\n",
    "        date_cols = [col for col in df.columns if 'DATE' in col and col != 'LAST_MODIFIED_DATE']\n",
    "        for i in range(len(date_cols)-1):\n",
    "            for j in range(i+1, len(date_cols)):\n",
    "                col1, col2 = date_cols[i], date_cols[j]\n",
    "                invalid_dates = df[(df[col1].notna()) & (df[col2].notna()) & (df[col2] < df[col1])]\n",
    "                if len(invalid_dates) > 0:\n",
    "                    print(f\"   - Records with {col2} before {col1}: {len(invalid_dates)}\")\n",
    "        \n",
    "        # b. Check for missing candidate IDs\n",
    "        if 'CANDIDATE_ID' in df.columns:\n",
    "            missing_ids = df[df['CANDIDATE_ID'].isna()]\n",
    "            print(f\"   - Records with missing candidate IDs: {len(missing_ids)}\")\n",
    "            \n",
    "        # c. Check for invalid statuses\n",
    "        if 'CANDIDATE_HISTORICAL_STATUS' in df.columns and 'candidate_status' in data:\n",
    "            valid_statuses = set(data['candidate_status']['CANDIDATE_HISTORICAL_STATUS'])\n",
    "            invalid_statuses = df[~df['CANDIDATE_HISTORICAL_STATUS'].isin(valid_statuses)]\n",
    "            print(f\"   - Records with invalid status values: {len(invalid_statuses)}\")\n",
    "            if len(invalid_statuses) > 0:\n",
    "                display(invalid_statuses['CANDIDATE_HISTORICAL_STATUS'].value_counts())\n",
    "    \n",
    "    elif table_name == 'department':\n",
    "        # a. Check for departments that are their own parent\n",
    "        if 'DEPARTMENT_ID' in df.columns and 'PARENT_DEPARTMENT_ID' in df.columns:\n",
    "            self_parent = df[df['DEPARTMENT_ID'] == df['PARENT_DEPARTMENT_ID']]\n",
    "            print(f\"   - Departments that are their own parent: {len(self_parent)}\")\n",
    "            if len(self_parent) > 0:\n",
    "                display(self_parent.head())\n",
    "            \n",
    "        # b. Check for consistency in naming patterns\n",
    "        if 'DEPARTMENT_NAME' in df.columns:\n",
    "            missing_sd = df[~df['DEPARTMENT_NAME'].str.contains('- SD')]\n",
    "            print(f\"   - Departments without '- SD' in name: {len(missing_sd)}\")\n",
    "            if len(missing_sd) > 0:\n",
    "                display(missing_sd['DEPARTMENT_NAME'].head())\n",
    "                \n",
    "            \n",
    "    elif table_name == 'candidate_status':\n",
    "        # Check for duplicate status values\n",
    "        if 'CANDIDATE_HISTORICAL_STATUS' in df.columns:\n",
    "            dup_status = df['CANDIDATE_HISTORICAL_STATUS'].duplicated().sum()\n",
    "            print(f\"   - Duplicate status values: {dup_status}\")\n",
    "            \n",
    "        # Check for missing stage mappings\n",
    "        if 'CANDIDATE_STAGE' in df.columns:\n",
    "            missing_stage = df[df['CANDIDATE_STAGE'].isna()]\n",
    "            print(f\"   - Statuses without stage mapping: {len(missing_stage)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aswatson",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
