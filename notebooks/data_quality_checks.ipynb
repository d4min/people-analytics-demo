{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Assessment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary to import db_connector script\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Add project root to sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "from db_connector import load_from_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_from_excel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines data quality assessment function:\n",
    "\n",
    "def assess_data_quality(df, table_name):\n",
    "    print(f\"\\n{'='*30} {table_name.upper()} DATA QUALITY {'='*30}\")\n",
    "\n",
    "    # 1. Check for duplicates\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"\\n1. Duplicates: {duplicates} ({duplicates/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    # 2. Check for missing values\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = df.isnull().sum() / len(df) * 100\n",
    "    missing_info = pd.DataFrame({\n",
    "        'Missing Values': missing,\n",
    "        'Percentage': missing_pct\n",
    "    })\n",
    "    print(\"\\n2. Missing Values:\")\n",
    "    display(missing_info[missing_info['Missing Values'] > 0].sort_values('Missing Values', ascending=False))\n",
    "    \n",
    "    # 3. Check data types\n",
    "    print(\"\\n3. Data Types:\")\n",
    "    display(pd.DataFrame(df.dtypes, columns=['Data Type']))\n",
    "    \n",
    "    # 4. Specific checks based on table\n",
    "    print(\"\\n4. Specific Quality Checks:\")\n",
    "\n",
    "    if table_name == 'requisitions':\n",
    "        # a. Check for requisitions with close date before open date\n",
    "        if 'OPEN_DATE' in df.columns and 'CLOSE_DATE' in df.columns:\n",
    "            invalid_dates = df[df['CLOSE_DATE'].notna() & (df['CLOSE_DATE'] < df['OPEN_DATE'])]\n",
    "            print(f\"   - Requisitions with close date before open date: {len(invalid_dates)}\")\n",
    "            if len(invalid_dates) > 0:\n",
    "                display(invalid_dates.head())\n",
    "        \n",
    "        # b. Check for unusual number of openings\n",
    "        if 'NUMBER_OF_OPENINGS' in df.columns:\n",
    "            unusual_openings = df[df['NUMBER_OF_OPENINGS'] > 10]  \n",
    "            print(f\"   - Requisitions with more than 10 openings: {len(unusual_openings)}\")\n",
    "            if len(unusual_openings) > 0:\n",
    "                value_counts = df['NUMBER_OF_OPENINGS'].value_counts().sort_index()\n",
    "                display(value_counts)\n",
    "            \n",
    "    elif table_name == 'candidate':\n",
    "        # a. Check for candidates with status dates out of order\n",
    "        date_cols = [col for col in df.columns if 'DATE' in col and col != 'LAST_MODIFIED_DATE']\n",
    "        for i in range(len(date_cols)-1):\n",
    "            for j in range(i+1, len(date_cols)):\n",
    "                col1, col2 = date_cols[i], date_cols[j]\n",
    "                invalid_dates = df[(df[col1].notna()) & (df[col2].notna()) & (df[col2] < df[col1])]\n",
    "                if len(invalid_dates) > 0:\n",
    "                    print(f\"   - Records with {col2} before {col1}: {len(invalid_dates)}\")\n",
    "        \n",
    "        # b. Check for missing candidate IDs\n",
    "        if 'CANDIDATE_ID' in df.columns:\n",
    "            missing_ids = df[df['CANDIDATE_ID'].isna()]\n",
    "            print(f\"   - Records with missing candidate IDs: {len(missing_ids)}\")\n",
    "            \n",
    "        # c. Check for invalid statuses\n",
    "        if 'CANDIDATE_HISTORICAL_STATUS' in df.columns and 'candidate_status' in data:\n",
    "            valid_statuses = set(data['candidate_status']['CANDIDATE_HISTORICAL_STATUS'])\n",
    "            invalid_statuses = df[~df['CANDIDATE_HISTORICAL_STATUS'].isin(valid_statuses)]\n",
    "            print(f\"   - Records with invalid status values: {len(invalid_statuses)}\")\n",
    "            if len(invalid_statuses) > 0:\n",
    "                display(invalid_statuses['CANDIDATE_HISTORICAL_STATUS'].value_counts())\n",
    "    \n",
    "    elif table_name == 'department':\n",
    "        # a. Check for departments that are their own parent\n",
    "        if 'DEPARTMENT_ID' in df.columns and 'PARENT_DEPARTMENT_ID' in df.columns:\n",
    "            self_parent = df[df['DEPARTMENT_ID'] == df['PARENT_DEPARTMENT_ID']]\n",
    "            print(f\"   - Departments that are their own parent: {len(self_parent)}\")\n",
    "            if len(self_parent) > 0:\n",
    "                display(self_parent.head())\n",
    "            \n",
    "        # b. Check for consistency in naming patterns\n",
    "        if 'DEPARTMENT_NAME' in df.columns:\n",
    "            missing_sd = df[~df['DEPARTMENT_NAME'].str.contains('- SD')]\n",
    "            print(f\"   - Departments without '- SD' in name: {len(missing_sd)}\")\n",
    "            if len(missing_sd) > 0:\n",
    "                display(missing_sd['DEPARTMENT_NAME'].head())\n",
    "                \n",
    "            \n",
    "    elif table_name == 'candidate_status':\n",
    "        # Check for duplicate status values\n",
    "        if 'CANDIDATE_HISTORICAL_STATUS' in df.columns:\n",
    "            dup_status = df['CANDIDATE_HISTORICAL_STATUS'].duplicated().sum()\n",
    "            print(f\"   - Duplicate status values: {dup_status}\")\n",
    "            \n",
    "        # Check for missing stage mappings\n",
    "        if 'CANDIDATE_STAGE' in df.columns:\n",
    "            missing_stage = df[df['CANDIDATE_STAGE'].isna()]\n",
    "            print(f\"   - Statuses without stage mapping: {len(missing_stage)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each pipeline should have a logical order of candidate statuses \n",
    "# e.g. New Submission -> In Review -> Interview -> Offer -> Hired\n",
    "# Or: New Submission -> In Review -> Rejected\n",
    "# NOT: Interview -> New Submission -> Rejected -> Offer\n",
    "\n",
    "def check_candidate_status_logic(df):\n",
    "    print(\"\\n\" + \"=\"*30 + \" CANDIDATE STATUS LOGIC CHECKS \" + \"=\"*30)\n",
    "\n",
    "    # First, ensure we have datetime for status dates\n",
    "    if 'HISTORICAL_STATUS_START_DATE' in df.columns:\n",
    "        if df['HISTORICAL_STATUS_START_DATE'].dtype != 'datetime64[ns]':\n",
    "            df['HISTORICAL_STATUS_START_DATE'] = pd.to_datetime(df['HISTORICAL_STATUS_START_DATE'], errors='coerce')\n",
    "\n",
    "    # Group by requisition and candidate to analyse each pipeline\n",
    "    pipeline_groups = df.groupby(['REQUISITION_ID', 'CANDIDATE_ID'])\n",
    "\n",
    "    # Get the last status for each pipeline\n",
    "    last_statuses = pipeline_groups.apply(lambda g: g.sort_values('HISTORICAL_STATUS_START_DATE').iloc[-1])\n",
    "\n",
    "    # Check distribution of final statuses\n",
    "    print(\"\\nDistribution of final candidate statuses:\")\n",
    "    final_status_counts = last_statuses['CANDIDATE_HISTORICAL_STATUS'].value_counts()\n",
    "    display(final_status_counts)\n",
    "\n",
    "    # Identify potentially problematic final statuses\n",
    "    expected_final_statuses = ['Hired', 'Rejected', 'Closed']\n",
    "    unexpected_final = last_statuses[~last_statuses['CANDIDATE_HISTORICAL_STATUS'].isin(expected_final_statuses)]\n",
    "    \n",
    "    print(f\"\\nPipelines not ending with expected final status (Hired/Rejected/Closed): {len(unexpected_final)} ({len(unexpected_final)/len(last_statuses)*100:.2f}%)\")\n",
    "    \n",
    "    if len(unexpected_final) > 0:\n",
    "        print(\"\\nTop unusual final statuses:\")\n",
    "        display(unexpected_final['CANDIDATE_HISTORICAL_STATUS'].value_counts().head(10))\n",
    "        \n",
    "        print(\"\\nSample of pipelines with unusual final status:\")\n",
    "        display(unexpected_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== CANDIDATE STATUS LOGIC CHECKS ==============================\n",
      "\n",
      "Distribution of final candidate statuses:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3s/27y6xzfx5j55fg4s9swmhjsc0000gn/T/ipykernel_25314/933882998.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  last_statuses = pipeline_groups.apply(lambda g: g.sort_values('HISTORICAL_STATUS_START_DATE').iloc[-1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CANDIDATE_HISTORICAL_STATUS\n",
       "Closed               156967\n",
       "Hired                  4513\n",
       "In Review              4236\n",
       "New Submission         2174\n",
       "Assessment Centre       186\n",
       "Rejected                119\n",
       "Pre Offer xxx           105\n",
       "First Interview          73\n",
       "Phone Interview          72\n",
       "Second Interview         52\n",
       "Offer                    37\n",
       "Interview                 7\n",
       "Right to Work             5\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pipelines not ending with expected final status (Hired/Rejected/Closed): 6947 (4.12%)\n",
      "\n",
      "Top unusual final statuses:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CANDIDATE_HISTORICAL_STATUS\n",
       "In Review            4236\n",
       "New Submission       2174\n",
       "Assessment Centre     186\n",
       "Pre Offer xxx         105\n",
       "First Interview        73\n",
       "Phone Interview        72\n",
       "Second Interview       52\n",
       "Offer                  37\n",
       "Interview               7\n",
       "Right to Work           5\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of pipelines with unusual final status:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>REQUISITION_ID</th>\n",
       "      <th>PIPELINE_ID</th>\n",
       "      <th>SUBMISSION_DATE</th>\n",
       "      <th>CANDIDATE_ID</th>\n",
       "      <th>SUBMISSION_SOURCE</th>\n",
       "      <th>CANDIDATE_HISTORICAL_STATUS</th>\n",
       "      <th>HISTORICAL_STATUS_START_DATE</th>\n",
       "      <th>HISTORICAL_STATUS_END_DATE</th>\n",
       "      <th>LAST_MODIFIED_DATE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REQUISITION_ID</th>\n",
       "      <th>CANDIDATE_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219020</th>\n",
       "      <th>4542201.0</th>\n",
       "      <td>219020</td>\n",
       "      <td>5551981</td>\n",
       "      <td>2023-01-02 10:20:16</td>\n",
       "      <td>4542201.0</td>\n",
       "      <td>URL_p_Indeed Organic</td>\n",
       "      <td>Offer</td>\n",
       "      <td>2023-01-31 09:47:52</td>\n",
       "      <td>2023-01-31 12:01:10</td>\n",
       "      <td>2023-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250080</th>\n",
       "      <th>6239776.0</th>\n",
       "      <td>250080</td>\n",
       "      <td>6293748</td>\n",
       "      <td>2023-04-14 03:07:48</td>\n",
       "      <td>6239776.0</td>\n",
       "      <td>URL_p_Indeed Organic</td>\n",
       "      <td>New Submission</td>\n",
       "      <td>2023-04-14 03:07:48</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256021</th>\n",
       "      <th>4689810.0</th>\n",
       "      <td>256021</td>\n",
       "      <td>5662448</td>\n",
       "      <td>2023-01-11 19:58:13</td>\n",
       "      <td>4689810.0</td>\n",
       "      <td>URL_p_Indeed Organic</td>\n",
       "      <td>Pre Offer xxx</td>\n",
       "      <td>2023-01-12 14:22:37</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325363</th>\n",
       "      <th>5629238.0</th>\n",
       "      <td>325363</td>\n",
       "      <td>6072071</td>\n",
       "      <td>2023-03-08 17:05:33</td>\n",
       "      <td>5629238.0</td>\n",
       "      <td>URL_p_Indeed Organic</td>\n",
       "      <td>New Submission</td>\n",
       "      <td>2023-03-08 17:05:33</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-03-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330742</th>\n",
       "      <th>4791189.0</th>\n",
       "      <td>330742</td>\n",
       "      <td>5726903</td>\n",
       "      <td>2023-01-20 22:53:03</td>\n",
       "      <td>4791189.0</td>\n",
       "      <td>Superdrug - Mobile Friendly - 050918</td>\n",
       "      <td>New Submission</td>\n",
       "      <td>2023-01-20 22:53:03</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-01-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             REQUISITION_ID  PIPELINE_ID      SUBMISSION_DATE  CANDIDATE_ID                     SUBMISSION_SOURCE CANDIDATE_HISTORICAL_STATUS HISTORICAL_STATUS_START_DATE HISTORICAL_STATUS_END_DATE LAST_MODIFIED_DATE\n",
       "REQUISITION_ID CANDIDATE_ID                                                                                                                                                                                                             \n",
       "219020         4542201.0             219020      5551981  2023-01-02 10:20:16     4542201.0                  URL_p_Indeed Organic                      Offer           2023-01-31 09:47:52        2023-01-31 12:01:10         2023-01-31\n",
       "250080         6239776.0             250080      6293748  2023-04-14 03:07:48     6239776.0                  URL_p_Indeed Organic              New Submission          2023-04-14 03:07:48                        NaT         2023-04-14\n",
       "256021         4689810.0             256021      5662448  2023-01-11 19:58:13     4689810.0                  URL_p_Indeed Organic               Pre Offer xxx          2023-01-12 14:22:37                        NaT         2023-01-12\n",
       "325363         5629238.0             325363      6072071  2023-03-08 17:05:33     5629238.0                  URL_p_Indeed Organic              New Submission          2023-03-08 17:05:33                        NaT         2023-03-08\n",
       "330742         4791189.0             330742      5726903  2023-01-20 22:53:03     4791189.0  Superdrug - Mobile Friendly - 050918              New Submission          2023-01-20 22:53:03                        NaT         2023-01-20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_candidate_status_logic(data['candidate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aswatson",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
